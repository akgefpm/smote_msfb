{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea83ef86-78dd-4452-b45a-5aac32c244e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting liac-arff\n",
      "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
      "Building wheels for collected packages: liac-arff\n",
      "  Building wheel for liac-arff (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11731 sha256=678ceac815a25266fcf53a5b0ffe78bccd087589bc21ce75bc7af8d0bfae12d6\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/a2/de/68/bf3972de3ecb31e32bef59a7f4c75f0687a3674c476b347c14\n",
      "Successfully built liac-arff\n",
      "Installing collected packages: liac-arff\n",
      "Successfully installed liac-arff-2.5.0\n"
     ]
    }
   ],
   "source": [
    "! pip install liac-arff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e9ab841e-7472-45d8-9d24-247a86bd375b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\n",
      "  Downloading pyarrow-17.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 40.0 MB 5.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.8/site-packages (from pyarrow) (1.21.1)\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-17.0.0\n"
     ]
    }
   ],
   "source": [
    "! pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c9f8e08-44bb-431e-a7b8-90d725ca0441",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checks to be executed for each dataset\n",
    "## 1. The unique values across the entire dataset should be 0 or 1 only\n",
    "## 2. There should NOT be any columns in the co-variate space with all value equal. Let's remove those columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1afe6891-00f4-415a-b52b-0185a4bf4981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arff\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "671bd7ff-2347-46d8-bb1f-4d525f0ca7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/repos/smote_msfb/public_datasets/enron/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec235a55-f63f-43b2-baac-bcc3912b8f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .arff file - With full data in one file\n",
    "with open(path + 'enron.arff', 'r') as f:\n",
    "    dataset = arff.load(f)\n",
    "    \n",
    "# Extract data and attributes\n",
    "data = dataset['data']\n",
    "attributes = dataset['attributes']\n",
    "\n",
    "# Create DataFrame\n",
    "columns = [attr[0] for attr in attributes]\n",
    "df = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbab1187-1cf3-4568-a878-cc6f5116f5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the delicious.arff file : (1702, 1054)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the delicious.arff file :\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6768b85-6836-4031-90f5-282951e1f5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n"
     ]
    }
   ],
   "source": [
    "### Get the position of the first Label columns\n",
    "col_position = df.columns.get_loc(\"A.A8\")  ## The first label column in the dataset\n",
    "print(col_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c34ebb9-bbc7-4591-9405-8e42ce110cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0', '00', '000', '01', '02', '03', '04', '05', '06', '07',\n",
       "       ...\n",
       "       'C.C3', 'D.D10', 'D.D18', 'B.B13', 'D.D17', 'B.B10', 'C.C1', 'D.D4',\n",
       "       'C.C13', 'D.D14'],\n",
       "      dtype='object', length=1054)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31203618-52b0-4071-8a2c-a0fc621e1033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0', '00', '000', '01', '02', '03', '04', '05', '06', '07',\n",
       "       ...\n",
       "       'workers', 'working', 'world', 'writer', 'writers', 'www', 'year',\n",
       "       'years', 'yesterday', 'york'],\n",
       "      dtype='object', length=1001)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,:col_position].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae764af1-cd47-4388-b0a3-dc6d68f33143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '1']\n"
     ]
    }
   ],
   "source": [
    "##Check if the unique values across the entire co-variate space is 0 and 1 only or not\n",
    "unique_values = np.unique(df.iloc[:, :col_position].values)\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3b1c775-4dea-4711-b164-86e9ba0b4849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '1']\n"
     ]
    }
   ],
   "source": [
    "## Check if the unique values in the mulit labels is 0 and 1 only or not\n",
    "unique_values = np.unique(df.iloc[:,col_position:].values)\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "947ccbe4-54e8-42a8-a329-e475251b81c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the non_constant_cols : (1702, 1001)\n",
      "Shape of df_cleaned : (1702, 1054)\n"
     ]
    }
   ],
   "source": [
    "## Check to drop columns from the dataset with same values for all rows\n",
    "\n",
    "# Subset the first 1836 columns\n",
    "features = df.iloc[:, :col_position]\n",
    "\n",
    "# Identify columns with more than one unique value\n",
    "non_constant_cols = features.loc[:, features.nunique(dropna=False) > 1]\n",
    "\n",
    "print(\"Shape of the non_constant_cols :\", non_constant_cols.shape)\n",
    "\n",
    "# Concatenate with the remaining part of the DataFrame (e.g., label columns)\n",
    "df_cleaned = pd.concat([non_constant_cols, df.iloc[:, col_position:]], axis=1)\n",
    "\n",
    "print(\"Shape of df_cleaned :\", df_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92f9bae4-6ea8-4015-9303-748038d58c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "## No columns were deleted during constant value checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b711968-b174-48c9-9043-d3cea269b41d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0', '00', '000', '01', '02', '03', '04', '05', '06', '07',\n",
       "       ...\n",
       "       'workers', 'working', 'world', 'writer', 'writers', 'www', 'year',\n",
       "       'years', 'yesterday', 'york'],\n",
       "      dtype='object', length=1001)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,:col_position].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59a8c12f-696e-40e4-a483-e3a206231d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Rename the co-variate feature space of the dataset\n",
    "\n",
    "# Generate new column names\n",
    "new_feature_names = [f\"f_{i}\" for i in range(col_position)]\n",
    "\n",
    "# Assign the new names to the first 1836 columns\n",
    "df_cleaned.columns.values[:col_position] = new_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48cad269-ec5e-4d89-a39d-2b946c7efc82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>...</th>\n",
       "      <th>C.C3</th>\n",
       "      <th>D.D10</th>\n",
       "      <th>D.D18</th>\n",
       "      <th>B.B13</th>\n",
       "      <th>D.D17</th>\n",
       "      <th>B.B10</th>\n",
       "      <th>C.C1</th>\n",
       "      <th>D.D4</th>\n",
       "      <th>C.C13</th>\n",
       "      <th>D.D14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1054 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  f_0 f_1 f_2 f_3 f_4 f_5 f_6 f_7 f_8 f_9  ... C.C3 D.D10 D.D18 B.B13 D.D17  \\\n",
       "0   0   0   0   0   0   0   0   0   0   0  ...    0     0     0     1     0   \n",
       "1   0   0   0   1   0   0   0   0   0   0  ...    0     0     0     0     0   \n",
       "2   0   0   0   0   0   0   0   0   0   0  ...    0     0     0     0     0   \n",
       "\n",
       "  B.B10 C.C1 D.D4 C.C13 D.D14  \n",
       "0     0    1    0     0     0  \n",
       "1     0    1    0     0     0  \n",
       "2     0    0    0     0     0  \n",
       "\n",
       "[3 rows x 1054 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "990caee0-7bf2-4767-b5da-8491bfe0a58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f22399c-a1ab-4bcd-9df9-a636ffb84ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_1: 0's = 0.9847, 1's = 0.0153\n",
      "target_2: 0's = 0.9624, 1's = 0.0376\n",
      "target_3: 0's = 0.9965, 1's = 0.0035\n",
      "target_4: 0's = 0.9847, 1's = 0.0153\n",
      "target_5: 0's = 0.9365, 1's = 0.0635\n",
      "target_6: 0's = 0.9512, 1's = 0.0488\n",
      "target_7: 0's = 0.4636, 1's = 0.5364\n",
      "target_8: 0's = 0.9753, 1's = 0.0247\n",
      "target_9: 0's = 0.9941, 1's = 0.0059\n",
      "target_10: 0's = 0.9853, 1's = 0.0147\n",
      "target_11: 0's = 0.9929, 1's = 0.0071\n",
      "target_12: 0's = 0.6868, 1's = 0.3132\n",
      "target_13: 0's = 0.9266, 1's = 0.0734\n",
      "target_14: 0's = 0.9031, 1's = 0.0969\n",
      "target_15: 0's = 0.4976, 1's = 0.5024\n",
      "target_16: 0's = 0.9894, 1's = 0.0106\n",
      "target_17: 0's = 0.9947, 1's = 0.0053\n",
      "target_18: 0's = 0.9871, 1's = 0.0129\n",
      "target_19: 0's = 0.9777, 1's = 0.0223\n",
      "target_20: 0's = 0.9877, 1's = 0.0123\n",
      "target_21: 0's = 0.9371, 1's = 0.0629\n",
      "target_22: 0's = 0.8966, 1's = 0.1034\n",
      "target_23: 0's = 0.9677, 1's = 0.0323\n",
      "target_24: 0's = 0.9436, 1's = 0.0564\n",
      "target_25: 0's = 0.9548, 1's = 0.0452\n",
      "target_26: 0's = 0.6005, 1's = 0.3995\n",
      "target_27: 0's = 0.9924, 1's = 0.0076\n",
      "target_28: 0's = 0.9959, 1's = 0.0041\n",
      "target_29: 0's = 0.9882, 1's = 0.0118\n",
      "target_30: 0's = 0.9271, 1's = 0.0729\n",
      "target_31: 0's = 0.9982, 1's = 0.0018\n",
      "target_32: 0's = 0.9630, 1's = 0.0370\n",
      "target_33: 0's = 0.9959, 1's = 0.0041\n",
      "target_34: 0's = 0.9853, 1's = 0.0147\n",
      "target_35: 0's = 0.9871, 1's = 0.0129\n",
      "target_36: 0's = 0.9953, 1's = 0.0047\n",
      "target_37: 0's = 0.9924, 1's = 0.0076\n",
      "target_38: 0's = 0.9806, 1's = 0.0194\n",
      "target_39: 0's = 0.9924, 1's = 0.0076\n",
      "target_40: 0's = 0.8537, 1's = 0.1463\n",
      "target_41: 0's = 0.9912, 1's = 0.0088\n",
      "target_42: 0's = 0.9835, 1's = 0.0165\n",
      "target_43: 0's = 0.9712, 1's = 0.0288\n",
      "target_44: 0's = 0.9583, 1's = 0.0417\n",
      "target_45: 0's = 0.9236, 1's = 0.0764\n",
      "target_46: 0's = 0.9994, 1's = 0.0006\n",
      "target_47: 0's = 0.8173, 1's = 0.1827\n",
      "target_48: 0's = 0.9988, 1's = 0.0012\n",
      "target_49: 0's = 0.9894, 1's = 0.0106\n",
      "target_50: 0's = 0.8807, 1's = 0.1193\n",
      "target_51: 0's = 0.9882, 1's = 0.0118\n",
      "target_52: 0's = 0.9959, 1's = 0.0041\n",
      "target_53: 0's = 0.9982, 1's = 0.0018\n"
     ]
    }
   ],
   "source": [
    "## Dataset is highly imbalanced\n",
    "\n",
    "# Slice only the label columns\n",
    "label_data = df_cleaned.iloc[:, col_position:]\n",
    "\n",
    "# Calculate proportions of 0's and 1's for each column\n",
    "for col in label_data.columns:\n",
    "    value_counts = label_data[col].value_counts(normalize=True).sort_index()\n",
    "    prop_0 = value_counts.get(0, 0)\n",
    "    prop_1 = value_counts.get(1, 0)\n",
    "    print(f\"{col}: 0's = {prop_0:.4f}, 1's = {prop_1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83f4ab6f-380d-49b2-96d6-c471dfcfa534",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rename all the response variables as target_X\n",
    "\n",
    "# Total number of columns\n",
    "total_cols = df_cleaned.shape[1]\n",
    "\n",
    "# Generate new names for response variables\n",
    "num_targets = total_cols - col_position\n",
    "new_target_names = [f\"target_{i+1}\" for i in range(num_targets)]\n",
    "\n",
    "# Apply the new names\n",
    "df_cleaned.columns.values[col_position:] = new_target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "afadd7c1-a6ee-49bd-b10c-377a717f230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.columns = df_cleaned.columns.map(lambda x: \"_\".join(map(str, x)) if isinstance(x, tuple) else str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a51fc39d-1325-4c94-b889-2b760b239648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted target_7: pre ratio=1.16, post ratio=0.13\n",
      "Adjusted target_15: pre ratio=1.01, post ratio=0.14\n"
     ]
    }
   ],
   "source": [
    "## Meaning the no. of minority > no. of majority samples. When ever this happens we need to --> Random convert minority samples to \n",
    "## majority by flipping the response variable to 0 from 1. Such that the no. of minority is 25% of the majority samples.\n",
    "\n",
    "for target_col in [c for c in df_cleaned.columns if c.startswith(\"target_\")]:\n",
    "    counts = df_cleaned[target_col].value_counts()\n",
    "    num_majority = counts.get(0, 0)\n",
    "    num_minority = counts.get(1, 0)\n",
    "\n",
    "    if num_minority > num_majority:\n",
    "        # Pre ratio\n",
    "        pre_ratio = num_minority / num_majority if num_majority > 0 else float('inf')\n",
    "\n",
    "        # Desired minority count = 25% of majority\n",
    "        desired_minority = int(0.25 * num_majority)\n",
    "\n",
    "        # Number of flips needed\n",
    "        num_to_flip = num_minority - desired_minority\n",
    "        minority_indices = df_cleaned[df_cleaned[target_col] == 1].sample(\n",
    "            n=num_to_flip, random_state=42\n",
    "        ).index\n",
    "\n",
    "        # Flip selected 1's to 0\n",
    "        df_cleaned.loc[minority_indices, target_col] = 0\n",
    "\n",
    "        # Post ratio\n",
    "        counts_post = df_cleaned[target_col].value_counts()\n",
    "        post_ratio = counts_post.get(1, 0) / counts_post.get(0, 1)\n",
    "\n",
    "        print(f\"Adjusted {target_col}: pre ratio={pre_ratio:.2f}, post ratio={post_ratio:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ab5f240a-073a-4db8-9f11-7ab6799d7da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0_count  1_count\n",
      "target_1      1676       26\n",
      "target_2      1638       64\n",
      "target_3      1696        6\n",
      "target_4      1676       26\n",
      "target_5      1594      108\n",
      "target_6      1619       83\n",
      "target_7      1505      197\n",
      "target_8      1660       42\n",
      "target_9      1692       10\n",
      "target_10     1677       25\n",
      "target_11     1690       12\n",
      "target_12     1169      533\n",
      "target_13     1577      125\n",
      "target_14     1537      165\n",
      "target_15     1491      211\n",
      "target_16     1684       18\n",
      "target_17     1693        9\n",
      "target_18     1680       22\n",
      "target_19     1664       38\n",
      "target_20     1681       21\n",
      "target_21     1595      107\n",
      "target_22     1526      176\n",
      "target_23     1647       55\n",
      "target_24     1606       96\n",
      "target_25     1625       77\n",
      "target_26     1022      680\n",
      "target_27     1689       13\n",
      "target_28     1695        7\n",
      "target_29     1682       20\n",
      "target_30     1578      124\n",
      "target_31     1699        3\n",
      "target_32     1639       63\n",
      "target_33     1695        7\n",
      "target_34     1677       25\n",
      "target_35     1680       22\n",
      "target_36     1694        8\n",
      "target_37     1689       13\n",
      "target_38     1669       33\n",
      "target_39     1689       13\n",
      "target_40     1453      249\n",
      "target_41     1687       15\n",
      "target_42     1674       28\n",
      "target_43     1653       49\n",
      "target_44     1631       71\n",
      "target_45     1572      130\n",
      "target_46     1701        1\n",
      "target_47     1391      311\n",
      "target_48     1700        2\n",
      "target_49     1684       18\n",
      "target_50     1499      203\n",
      "target_51     1682       20\n",
      "target_52     1695        7\n",
      "target_53     1699        3\n"
     ]
    }
   ],
   "source": [
    "# Collect counts for all target_* columns\n",
    "counts_summary = {}\n",
    "\n",
    "for col in df_cleaned.columns:\n",
    "    if col.startswith(\"target_\"):\n",
    "        counts_summary[col] = df_cleaned[col].value_counts().to_dict()\n",
    "\n",
    "# Convert to DataFrame for easy viewing\n",
    "summary_df = pd.DataFrame(counts_summary).T.fillna(0).astype(int)\n",
    "summary_df.columns = [\"0_count\", \"1_count\"]  # reorder if needed\n",
    "\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "87e0ae6d-bcbc-49e5-b1ca-b6a54dd45981",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.to_csv(path + \"/Final_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3ecb1f8d-f615-4f47-928d-ea1af0ab19e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.columns = [str(col) for col in df_cleaned.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f30d63ab-6ff8-4417-b540-7f1872d56c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as Parquet (compressed with snappy)\n",
    "df_cleaned.to_parquet(\n",
    "    path + \"/processed_dataset.parquet\", \n",
    "    engine=\"pyarrow\", \n",
    "    compression=\"snappy\", \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eee049f-d8c4-4588-b54e-3e7e749bcd98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
