{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4539d9e7-9e64-4b88-ad9e-aca473de3abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b15c2a7-4c46-448b-8cc3-d1d02a40f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c31e95d5-596d-4038-8f92-a8bd1833a6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your downloaded .tar.gz file\n",
    "file_path = \"/repos/smote_msfb/public_datasets/polarity/review_polarity.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "419dca86-5263-4a0f-9652-c091b4295d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the archive\n",
    "with tarfile.open(file_path, \"r:gz\") as tar:\n",
    "    tar.extractall(path=\"./polarity_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b60b948e-09fa-472a-9a87-99b712f0a3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder paths\n",
    "pos_folder = \"./polarity_dataset/txt_sentoken/pos/\"\n",
    "neg_folder = \"./polarity_dataset/txt_sentoken/neg/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41a5a76c-ad78-43ea-9e98-e33fa3505eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all files and assign sentiment label\n",
    "def read_reviews(folder, label):\n",
    "    reviews = []\n",
    "    for file in os.listdir(folder):\n",
    "        with open(os.path.join(folder, file), encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "            reviews.append((text, label))\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44f602b3-bddf-423b-a979-23671e26a690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both positive and negative reviews\n",
    "pos_reviews = read_reviews(pos_folder, 1)\n",
    "neg_reviews = read_reviews(neg_folder, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7360cb25-39fb-4bc8-868a-e949ff533097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine and shuffle\n",
    "all_reviews = pos_reviews + neg_reviews\n",
    "df = pd.DataFrame(all_reviews, columns=[\"review\", \"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a6e8790-3393-4575-8627-05aab7cc6d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37411d3f-70b9-4240-9edf-eb00e33573fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Shuffle rows\n",
    "# df = df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da59ab73-59aa-4e57-b746-ace35d7ca9c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pitch black is a sheep in wolf's clothing . \\n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>voices . . . . . trey parker , matt stone , ge...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>along his carreer , mel gibson has collected s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when quentin tarantino made \" pulp fiction \" ,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>john cusack is the kind of actor who seems to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  pitch black is a sheep in wolf's clothing . \\n...          1\n",
       "1  voices . . . . . trey parker , matt stone , ge...          1\n",
       "2  along his carreer , mel gibson has collected s...          1\n",
       "3  when quentin tarantino made \" pulp fiction \" ,...          1\n",
       "4  john cusack is the kind of actor who seems to ...          1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show sample\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed2b9542-bd1d-4a46-a1be-0174239ed21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)  # Remove punctuation/numbers\n",
    "    tokens = text.split()\n",
    "    tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df[\"clean_review\"] = df[\"review\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "871df043-fefc-43eb-9069-3d4b6d8c7fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(binary=True, max_features=15000)  # or remove max_features for full vocabulary\n",
    "X = vectorizer.fit_transform(df[\"clean_review\"])\n",
    "y = df[\"sentiment\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebf6e664-800f-4f01-88b9-a31a47545902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 3: Combine features and label into one DataFrame ===\n",
    "final_data = pd.DataFrame(X.toarray(), columns=[f\"f_{i}\" for i in range(X.shape[1])])\n",
    "final_data[\"target\"] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f142afa3-27ee-4283-b523-e81795e13c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify covariate columns (start with \"f_\")\n",
    "covariate_cols = [col for col in final_data.columns if col.startswith(\"f_\")]\n",
    "\n",
    "# Keep only covariate columns that are not all zero\n",
    "nonzero_covariates = final_data[covariate_cols].loc[:, (final_data[covariate_cols] != 0).any(axis=0)]\n",
    "\n",
    "# Combine with the target column\n",
    "final_data_cleaned = pd.concat([nonzero_covariates, final_data[\"target\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9af47fd-2f86-4bcd-9716-d8f6df3d612d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>...</th>\n",
       "      <th>f_14991</th>\n",
       "      <th>f_14992</th>\n",
       "      <th>f_14993</th>\n",
       "      <th>f_14994</th>\n",
       "      <th>f_14995</th>\n",
       "      <th>f_14996</th>\n",
       "      <th>f_14997</th>\n",
       "      <th>f_14998</th>\n",
       "      <th>f_14999</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 15001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   f_0  f_1  f_2  f_3  f_4  f_5  f_6  f_7  f_8  f_9  ...  f_14991  f_14992  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0  ...        0        0   \n",
       "1    0    0    0    0    0    0    0    0    0    0  ...        0        0   \n",
       "2    0    0    0    0    0    0    0    0    0    0  ...        0        0   \n",
       "\n",
       "   f_14993  f_14994  f_14995  f_14996  f_14997  f_14998  f_14999  target  \n",
       "0        0        0        0        0        0        0        0       1  \n",
       "1        0        0        0        0        0        0        0       1  \n",
       "2        0        0        0        0        0        0        0       1  \n",
       "\n",
       "[3 rows x 15001 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0b394ca-c362-4e39-b8d8-0b14f38742ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns where all values are 0\n",
    "final_data = final_data.loc[:, (final_data != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a14d406-7c37-46ab-af7f-96fcbbff853e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts:\n",
      " target\n",
      "1    1000\n",
      "0    1000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Proportions:\n",
      " target\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Counts of each class\n",
    "print(\"Counts:\\n\", final_data[\"target\"].value_counts())\n",
    "\n",
    "# Proportions of each class\n",
    "print(\"\\nProportions:\\n\", final_data[\"target\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b6ba827-4a47-4f85-9616-9b2bc91a2ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a15b70d-b9fd-43af-89a8-2ba9845b6460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 5 imbalanced datasets saved as Parquet files (compressed).\n"
     ]
    }
   ],
   "source": [
    "# Separate majority and minority classes\n",
    "majority_class = final_data[final_data[\"target\"] == 1]\n",
    "minority_class = final_data[final_data[\"target\"] == 0]\n",
    "\n",
    "# Define percentages\n",
    "percentages = [0.10, 0.15, 0.20, 0.25, 0.30]\n",
    "\n",
    "# Output directory (you can change this)\n",
    "output_dir = \"/repos/smote_msfb/public_datasets/polarity/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create and save each variant\n",
    "for pct in percentages:\n",
    "    n_samples = int(len(majority_class) * pct)\n",
    "    minority_sample = minority_class.sample(n=n_samples, random_state=42)\n",
    "    \n",
    "    # Combine with full majority\n",
    "    imbalanced_data = pd.concat([majority_class, minority_sample], ignore_index=True)\n",
    "    \n",
    "    # Shuffle\n",
    "    imbalanced_data = imbalanced_data.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    # File path (Parquet instead of CSV)\n",
    "    parquet_filename = f\"imbalanced_{int(pct * 100)}pct.parquet\"\n",
    "    parquet_path = os.path.join(output_dir, parquet_filename)\n",
    "    \n",
    "    # Save Parquet file with compression\n",
    "    imbalanced_data.to_parquet(\n",
    "        parquet_path, \n",
    "        engine=\"pyarrow\", \n",
    "        compression=\"snappy\", \n",
    "        index=False\n",
    "    )\n",
    "\n",
    "print(\"All 5 imbalanced datasets saved as Parquet files (compressed).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4baee79-1fec-473e-9891-070e086193dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 5 imbalanced datasets saved as zipped CSV files.\n"
     ]
    }
   ],
   "source": [
    "# Separate majority and minority classes\n",
    "majority_class = final_data[final_data[\"target\"] == 1]\n",
    "minority_class = final_data[final_data[\"target\"] == 0]\n",
    "\n",
    "# Define percentages\n",
    "percentages = [0.10, 0.15, 0.20, 0.25, 0.30]\n",
    "\n",
    "# Output directory (you can change this)\n",
    "output_dir = \"/repos/smote_msfb/public_datasets/polarity/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create and save each variant\n",
    "for pct in percentages:\n",
    "    n_samples = int(len(majority_class) * pct)\n",
    "    minority_sample = minority_class.sample(n=n_samples, random_state=42)\n",
    "    \n",
    "    # Combine with full majority\n",
    "    imbalanced_data = pd.concat([majority_class, minority_sample], ignore_index=True)\n",
    "    \n",
    "    # Shuffle\n",
    "    imbalanced_data = imbalanced_data.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # File paths\n",
    "    csv_filename = f\"imbalanced_{int(pct * 100)}pct.csv\"\n",
    "    zip_filename = f\"imbalanced_{int(pct * 100)}pct.zip\"\n",
    "    csv_path = os.path.join(output_dir, csv_filename)\n",
    "    zip_path = os.path.join(output_dir, zip_filename)\n",
    "\n",
    "    # Save CSV\n",
    "    imbalanced_data.to_csv(csv_path, index=False)\n",
    "\n",
    "    # Zip the file\n",
    "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        zipf.write(csv_path, arcname=csv_filename)\n",
    "\n",
    "    # Remove the raw CSV to keep only zipped version\n",
    "    os.remove(csv_path)\n",
    "\n",
    "print(\"All 5 imbalanced datasets saved as zipped CSV files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ace4352-cf66-49fe-acf1-5a714b942b8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
