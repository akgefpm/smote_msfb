{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea83ef86-78dd-4452-b45a-5aac32c244e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install liac-arff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9f8e08-44bb-431e-a7b8-90d725ca0441",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checks to be executed for each dataset\n",
    "## 1. The unique values across the entire dataset should be 0 or 1 only\n",
    "## 2. There should NOT be any columns in the co-variate space with all value equal. Let's remove those columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afe6891-00f4-415a-b52b-0185a4bf4981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arff\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671bd7ff-2347-46d8-bb1f-4d525f0ca7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/repos/smote_msfb/public_datasets/tmc2007/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec235a55-f63f-43b2-baac-bcc3912b8f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .arff file - With full data in one file\n",
    "with open(path + 'tmc2007.arff', 'r') as f:\n",
    "    dataset = arff.load(f)\n",
    "    \n",
    "# Extract data and attributes\n",
    "data = dataset['data']\n",
    "attributes = dataset['attributes']\n",
    "\n",
    "# Create DataFrame\n",
    "columns = [attr[0] for attr in attributes]\n",
    "df = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbab1187-1cf3-4568-a878-cc6f5116f5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of the medical.arff file :\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6768b85-6836-4031-90f5-282951e1f5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the position of the first Label columns\n",
    "col_position = df.columns.get_loc(\"class01\")  ## The first label column in the dataset\n",
    "print(col_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c34ebb9-bbc7-4591-9405-8e42ce110cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31203618-52b0-4071-8a2c-a0fc621e1033",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,:col_position+1].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae764af1-cd47-4388-b0a3-dc6d68f33143",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Check if the unique values across the entire co-variate space is 0 and 1 only or not\n",
    "unique_values = np.unique(df.iloc[:, :col_position].values)\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b1c775-4dea-4711-b164-86e9ba0b4849",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if the unique values in the mulit labels is 0 and 1 only or not\n",
    "unique_values = np.unique(df.iloc[:,col_position:].values)\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947ccbe4-54e8-42a8-a329-e475251b81c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check to drop columns from the dataset with same values for all rows\n",
    "\n",
    "# Subset the first 1836 columns\n",
    "features = df.iloc[:, :col_position]\n",
    "\n",
    "# Identify columns with more than one unique value\n",
    "non_constant_cols = features.loc[:, features.nunique(dropna=False) > 1]\n",
    "\n",
    "print(\"Shape of the non_constant_cols :\", non_constant_cols.shape)\n",
    "\n",
    "# Concatenate with the remaining part of the DataFrame (e.g., label columns)\n",
    "df_cleaned = pd.concat([non_constant_cols, df.iloc[:, col_position:]], axis=1)\n",
    "\n",
    "print(\"Shape of df_cleaned :\", df_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f9bae4-6ea8-4015-9303-748038d58c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "## WE REMOVE A LOT OF COLUMNS WITH SAME VALUE ACROSS ALL ROWS. ALMOST 90% OF THE COLUMNS ARE GONE\n",
    "\n",
    "col_position = non_constant_cols.shape[1]\n",
    "\n",
    "col_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b711968-b174-48c9-9043-d3cea269b41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.iloc[:,:col_position+1].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a8c12f-696e-40e4-a483-e3a206231d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Rename the co-variate feature space of the dataset\n",
    "\n",
    "# Generate new column names\n",
    "new_feature_names = [f\"f_{i}\" for i in range(col_position)]\n",
    "\n",
    "# Assign the new names to the first 1836 columns\n",
    "df_cleaned.columns.values[:col_position] = new_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cad269-ec5e-4d89-a39d-2b946c7efc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e89edaa-9524-4abc-a807-99f63cb9371c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.drop('class02', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f22399c-a1ab-4bcd-9df9-a636ffb84ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset is highly imbalanced\n",
    "\n",
    "# Slice only the label columns\n",
    "label_data = df_cleaned.iloc[:, col_position:]\n",
    "\n",
    "# Calculate proportions of 0's and 1's for each column\n",
    "for col in label_data.columns:\n",
    "    value_counts = label_data[col].value_counts(normalize=True).sort_index()\n",
    "    prop_0 = value_counts.get(0, 0)\n",
    "    prop_1 = value_counts.get(1, 0)\n",
    "    print(f\"{col}: 0's = {prop_0:.4f}, 1's = {prop_1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fd9029-b4e4-4c57-8491-501c528ba023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f4ab6f-380d-49b2-96d6-c471dfcfa534",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rename all the response variables as target_X\n",
    "\n",
    "# Total number of columns\n",
    "total_cols = df_cleaned.shape[1]\n",
    "\n",
    "# Generate new names for response variables\n",
    "num_targets = total_cols - col_position\n",
    "new_target_names = [f\"target_{i+1}\" for i in range(num_targets)]\n",
    "\n",
    "# Apply the new names\n",
    "df_cleaned.columns.values[col_position:] = new_target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5633cc-b171-4ab6-b449-b1502a7cf256",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a553e0-2910-4cf3-be49-e8785334cccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.loc[:, (df_cleaned != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9d8e7b-6576-4b8b-bfd0-6061245882eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be10f9a2-5205-440a-a669-d569276e071d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.columns = [str(col) for col in df_cleaned.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecb1f8d-f615-4f47-928d-ea1af0ab19e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as Parquet (compressed with snappy)\n",
    "df_cleaned.to_parquet(\n",
    "    path + \"/Final_dataset.parquet\", \n",
    "    engine=\"pyarrow\", \n",
    "    compression=\"snappy\", \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e0ae6d-bcbc-49e5-b1ca-b6a54dd45981",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.to_csv(path + \"/Final_dataset.zip\", index=False, compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1089e320-0732-4eda-b791-5ea6382310a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
