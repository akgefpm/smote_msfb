{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312698e8-0bba-473c-b208-d26cd3ef5b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rotten Tomatoes Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb1fcc2-36f2-4a75-8005-06d9ba2e0f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d00c5d6-3a09-49a7-a0f3-f2315559bce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091e2aa7-bdb3-4f89-9a53-ee53bd3fae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download NLTK resources if not already present\n",
    "import nltk\n",
    "nltk.download('punkt', force=True)\n",
    "nltk.download('stopwords', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ae18a8-afe4-4f6e-952b-749979e7ef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/repos/LAL/Public_Datasets/subjectivity/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bada011-473e-4d4d-816d-42c5c9e380d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the subjective and objective sentences using 'latin1' encoding\n",
    "with open(path + \"quote.tok.gt9.5000\", \"r\", encoding=\"latin1\") as f_subj:\n",
    "    subjective = f_subj.readlines()\n",
    "\n",
    "with open(path + \"plot.tok.gt9.5000\", \"r\", encoding=\"latin1\") as f_obj:\n",
    "    objective = f_obj.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dcb185-5142-499a-aebf-cd9634ee6de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with labels\n",
    "subj_df = pd.DataFrame({'text': subjective, 'target': 1})\n",
    "obj_df = pd.DataFrame({'text': objective, 'target': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3588bc5c-ed10-4b57-9bdd-fbc61c38332f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine datasets\n",
    "data = pd.concat([subj_df, obj_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3044fe1b-9277-4cea-93f9-b53db6449232",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f63df1-fb92-427c-a7c1-c547ad45b9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower().translate(punct_table)\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c3021f-5d23-43a2-b667-ac9f93053bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "data[\"clean_text\"] = data[\"text\"].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d974d4-b938-470d-bf12-97bd63eab338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize using Binary Bag-of-Words\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "X = vectorizer.fit_transform(data[\"clean_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f9f50a-a001-491d-b3b2-229ae75da34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame and rename columns to f_1, f_2, ...\n",
    "X_df = pd.DataFrame(X.toarray(), columns=[f\"f_{i+1}\" for i in range(X.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03fb4c4-bed7-4022-9f53-11fa13911c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499b0ad1-b08b-4426-a3c3-54dd53c40016",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(X_df.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ed8036-febd-4eb4-84cd-bafc0c0a22c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine with target\n",
    "final_df = pd.concat([X_df, data[\"target\"].reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c5e817-085e-4bf4-be84-1512555ea0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4db2255-2077-48a4-9b20-a9bd85490ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If y is a column in a DataFrame (e.g., df[\"target\"])\n",
    "print(final_df[\"target\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159805ef-f349-412a-ac74-cfd7d36e8ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data by class\n",
    "minority_df = final_df[final_df[\"target\"] == 1]\n",
    "majority_df = final_df[final_df[\"target\"] == 0]\n",
    "\n",
    "# Sample 20% of minority class\n",
    "minority_sample = minority_df.sample(frac=0.2, random_state=42)\n",
    "\n",
    "# Concatenate sampled minority and full majority\n",
    "imbalanced_df = pd.concat([minority_sample, majority_df], ignore_index=True)\n",
    "\n",
    "# Shuffle the resulting DataFrame\n",
    "#imbalanced_df = imbalanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Optional: check new class balance\n",
    "print(imbalanced_df[\"target\"].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec172c50-f438-438c-be96-4201b5309f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalanced_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91ae81c-f271-47f5-ab08-cee587fc1dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4761c53-11bb-4929-904c-5bcdfcc09f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as zipped CSV\n",
    "imbalanced_df.to_csv(path + \"Final_dataset_subjectivity.csv.zip\", index=False, compression=\"zip\")\n",
    "\n",
    "print(\"âœ… Preprocessed dataset saved as 'subjectivity_processed.csv.zip'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4604d326-d72d-4353-9251-b5f290637340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a09605-7212-4482-aa5a-33c64d5c0172",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
